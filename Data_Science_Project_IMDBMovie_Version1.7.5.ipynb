{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fundamentals of Data Science Project\n",
    "\n",
    "#features used:\n",
    "#  Numerical Features used: \n",
    "#     - actor1 Facebook likes, actor2 Facebook likes, actor3 Facebook likes, director Facebook likes, budget\n",
    "\n",
    "#  Text features used (treated as categorical data):\n",
    "#     - actor1 name, actor2 name, actor3 name, director name, country, content rating, language\n",
    "\n",
    "\n",
    "#Preprocessing-\n",
    "\n",
    "#  Text features:\n",
    "#    - Text data like top 3 actor names, director names, content rating, country and language have been treated as category \n",
    "#    - categorical data has been labelized and binarized for each feature column (each item in a feature column has unique label and binary form)\n",
    "#  Numerical feature preprocessing:\n",
    "#    - numerical data have been min max scaled by fitting to minmaxscaler  \n",
    "#  - rows with missing gross value and any empty major features have been eliminated\n",
    "#  - preprocessed numerical, categorical data and text data especially for gross prediction with categorical data in mind\n",
    "#  - Both numerical and text data has been used for gross prediction/regression.\n",
    "\n",
    "\n",
    "#Regression Model:\n",
    "#  Random forest Regression and Decision Tree Regression is applied to train and test evaluation.\n",
    "\n",
    "#Other models tried: SVR\n",
    "\n",
    "\n",
    "#Evaluation:\n",
    "#  5-fold cross validation\n",
    "#  Cross validation evaluated by Mean Absolute Error, Mean Squared Error.\n",
    "#  metrics:\n",
    "#    Mean Absolute Error, Mean Squared Error, Median Absolute Error, Explained Var Score, R^2 score have been calculated\n",
    "# Visualization: \n",
    "#   - actor1, actor2, actor3, director, country, content rating, language by mean gross have been visualized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import tree\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import KFold\n",
    "#from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, median_absolute_error, explained_variance_score, r2_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "global minval\n",
    "global maxval\n",
    "global min_max_scaler\n",
    "global catagory_features\n",
    "global number_features\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "text_features = ['genre', 'plot_keywords', 'movie_title']\n",
    "catagory_features = ['actor_1_name', 'actor_2_name', 'actor_3_name', 'director_name', 'country', 'content_rating', 'language']\n",
    "number_features = ['actor_1_facebook_likes', 'actor_2_facebook_likes', 'actor_3_facebook_likes', 'director_facebook_likes','cast_total_facebook_likes','budget', 'gross']\n",
    "all_selected_features = ['actor_1_name', 'actor_2_name', 'actor_3_name', 'director_name', 'country', 'content_rating', 'language', 'actor_1_facebook_likes', 'actor_2_facebook_likes', 'actor_3_facebook_likes', 'director_facebook_likes','cast_total_facebook_likes','budget', 'gross', 'genres']\n",
    "eliminate_if_empty_list = ['actor_1_name', 'actor_2_name', 'director_name', 'country', 'actor_1_facebook_likes', 'actor_2_facebook_likes', 'director_facebook_likes','cast_total_facebook_likes', 'gross']\n",
    "\n",
    "#preprocessing\n",
    "def data_import(path):\n",
    "    data = pd.read_csv(path)\n",
    "    return data\n",
    "\n",
    "def column_extract(data):\n",
    "    selected_data = data[all_selected_features]\n",
    "    return selected_data\n",
    "\n",
    "def empty_row_column_val_drop(data):\n",
    "    data = data.dropna(axis = 0, how = 'any', subset = eliminate_if_empty_list)\n",
    "    data = data.reset_index(drop = True)\n",
    "    return data\n",
    "\n",
    "def data_fillna(data): \n",
    "    for x in catagory_features:\n",
    "        data[x] = data[x].fillna('None').astype('category')\n",
    "    for y in number_features:\n",
    "        data[y] = data[y].fillna(0.0).astype(np.float)\n",
    "    return data\n",
    "\n",
    "def append_data(data1, data2):\n",
    "    result_data = np.append(data1, data2, 1)\n",
    "    return result_data\n",
    "    \n",
    "def preprocessing_numerical_minmax(data):\n",
    "    global min_max_scaler\n",
    "    scaled_data = min_max_scaler.fit_transform(data)\n",
    "    return scaled_data\n",
    "    \n",
    "def preprocessing_categorical(data):\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoded_data = label_encoder.fit_transform(data) \n",
    "    label_binarizer = preprocessing.LabelBinarizer()\n",
    "    label_binarized_data = label_binarizer.fit_transform(label_encoded_data) \n",
    "    return label_binarized_data\n",
    "\n",
    "def preprocessing_text(data):  \n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_vectorized_text = tfidf_vectorizer.fit_transform(data)  \n",
    "    return tfidf_vectorized_text\n",
    "\n",
    "#regression model training\n",
    "def train_stest_split(data, target, test_size):\n",
    "    train_data, test_data, train_target, test_target = train_test_split(data, target, test_size = test_size, random_state = 0)\n",
    "\n",
    "def regression_without_cross_validation(model, train_data, train_target, test_data): \n",
    "    model.fit(train_data, train_target)\n",
    "    prediction = model.predict(test_data)\n",
    "    return prediction\n",
    "\n",
    "def regression_with_cross_validation(model, data, target, n_fold, model_name):\n",
    "    print(\"Regression Model Name: \", model_name)\n",
    "    cross_val_score_mean_abs_err  = cross_val_score(model, data, target, scoring = 'mean_absolute_error', cv = n_fold) \n",
    "    print(\"\\nCross Validation Score (Mean Absolute Error)        : \\n\", -cross_val_score_mean_abs_err)\n",
    "    print(\"\\nCross Validation Score (Mean Absolute Error) (Mean) : \\n\", -cross_val_score_mean_abs_err.mean())\n",
    "    cross_val_score_mean_sqr_err  = cross_val_score(model, data, target, scoring = 'mean_squared_error', cv = n_fold)  \n",
    "    print(\"\\nCross Validation Score (Mean Squared Error)         : \\n\", -cross_val_score_mean_sqr_err)\n",
    "    print(\"\\nCross Validation Score (Mean Squared Error)  (Mean) : \\n\", -cross_val_score_mean_sqr_err.mean())\n",
    "    \n",
    "def regression_scores(original_val, predicted_val, model_name):\n",
    "    print(\"Regression Model Name: \", model_name)\n",
    "    mean_abs_error = mean_absolute_error(original_val, predicted_val) \n",
    "    mean_sqr_error = mean_squared_error(original_val, predicted_val)\n",
    "    median_abs_error = median_absolute_error(original_val, predicted_val)\n",
    "    explained_var_score = explained_variance_score(original_val, predicted_val)\n",
    "    r2__score = r2_score(original_val, predicted_val)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"\\nRegression Scores(train_test_split):\\n\")\n",
    "    print(\"Mean Absolute Error    :\", mean_abs_error)\n",
    "    print(\"Mean Squared Error     :\", mean_sqr_error)\n",
    "    print(\"Median Absolute Error  :\", median_abs_error)\n",
    "    print(\"Explained Var Score    :\", explained_var_score)\n",
    "    print(\"R^2 Score              :\", r2__score)\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "#simple task    \n",
    "def inverse_scaling(scaled_val):\n",
    "    unscaled_val = min_max_scaler.inverse_transform(scaled_val)\n",
    "    return unscaled_val\n",
    "\n",
    "def roundval(value):  \n",
    "    return value.round()\n",
    "\n",
    "def to_millions(value):   \n",
    "    return value / 10000000\n",
    "\n",
    "#evaluation    \n",
    "#plotting actual vs predicted for all data\n",
    "def prediction_performance_plot(original_val, predicted_val, model_name):\n",
    "    #inverse transform and convert to millions\n",
    "    original_val = to_millions(inverse_scaling(original_val)) \n",
    "    predicted_val = to_millions(inverse_scaling(predicted_val))\n",
    "    print(\"\\n\")\n",
    "    plt.title(\"\\nUsing Categorical and Numerical Features\\n\" + model_name + \": Actual Gross VS Predicted Gross(All Data)- \\n\")\n",
    "    plt.plot(original_val, c = 'g', label = \"Actual\")\n",
    "    plt.plot(predicted_val, c = 'b', label = \"Prediction\")\n",
    "    plt.legend([\"Actual Gross\", \"Predicted Gross\"], loc = 'center left', bbox_to_anchor = (1, 0.8))\n",
    "    plt.ylabel('Gross (In Millions)', fontsize = 14)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "#plotting actual vs predicted in a range    \n",
    "def prediction_performance_plot_range(original_val, predicted_val, start, end, model_name):\n",
    "    #inverse transform and convert to millions\n",
    "    original_val = to_millions(inverse_scaling(original_val)) \n",
    "    predicted_val = to_millions(inverse_scaling(predicted_val))\n",
    "    print(\"\\n\")\n",
    "    plt.title(\"\\nUsing Categorical and Numerical Features\\n\" + model_name + \" : Actual Gross VS Predicted Gross(Selected Range)\\n\")\n",
    "    plt.plot(original_val[start : end + 1], c = 'g', label = \"Actual\")\n",
    "    plt.plot(predicted_val[start : end + 1], c = 'b', label = \"Prediction\")\n",
    "    plt.legend([\"Actual Gross\", \"Predicted Gross\"], loc = 'center left', bbox_to_anchor = (1, 0.8))\n",
    "    plt.ylabel('Gross (In Millions)', fontsize = 14)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "#plotting actual vs predicted in a randomly    \n",
    "def prediction_performance_plot_random(original_val, predicted_val, n, model_name):\n",
    "    #inverse transform and convert to millions\n",
    "    original_val = to_millions(inverse_scaling(original_val)) \n",
    "    predicted_val = to_millions(inverse_scaling(predicted_val))\n",
    "    original_val_list = []\n",
    "    predicted_val_list = []\n",
    "    for k in range(n):\n",
    "        i = random.randint(0, len(predicted_val) - 1)\n",
    "        original_val_list.append(original_val[i])\n",
    "        predicted_val_list.append(predicted_val[i])\n",
    "    print(\"\\n\")\n",
    "    plt.title(\"\\nUsing Categorical and Numerical Features\\n\" + model_name + \": Actual Gross VS Predicted Gross(Randomly Selected)\\n\")\n",
    "    plt.plot(original_val_list, c = 'g', label = \"Actual\")\n",
    "    plt.plot(predicted_val_list, c = 'b', label = \"Prediction\")\n",
    "    plt.legend([\"Actual Value\", \"Predicted Value\"], loc = 'center left', bbox_to_anchor = (1, 0.8))\n",
    "    plt.ylabel('Gross (In Millions)', fontsize = 14)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "#printing actual vs predicted in a range \n",
    "def print_original_vs_predicted_seq(original_val, predicted_val, i, j, model_name):\n",
    "    #inverse transform and convert to millions\n",
    "    original_val = to_millions(inverse_scaling(original_val)) \n",
    "    predicted_val = to_millions(inverse_scaling(predicted_val))\n",
    "    \n",
    "    print(\"\\n\" , model_name, \": Comparision of Actual Gross VS Predicted Gross(Sequentional Sampling)\\n\")\n",
    "    if j<len(predicted_val):\n",
    "        for k in range(i, j + 1):\n",
    "            print(\"Actual Gross: \", original_val[k], \",   Predicted Gross: \", predicted_val[k])\n",
    "\n",
    "            \n",
    "#printing actual vs predicted in a randomly           \n",
    "def print_original_vs_predicted_rand(original_val, predicted_val, n, model_name):  \n",
    "    #inverse transform and convert to millions\n",
    "    original_val = to_millions(inverse_scaling(original_val)) \n",
    "    predicted_val = to_millions(inverse_scaling(predicted_val))\n",
    "    print(\"\\n\" , model_name , \" : Comparision of Actual Gross VS Predicted Gross(Random Sampling)[In Millions]\\n\")\n",
    "    for k in range(n):\n",
    "        i = random.randint(0, len(predicted_val) - 1)\n",
    "        print(\"Actual Gross: \", original_val[i], \",   Predicted Gross: \", predicted_val[i])\n",
    "\n",
    "        \n",
    "#plotting actual vs predicted in a randomly using a bar chart          \n",
    "def bar_plot_original_vs_predicted_rand(original_val, predicted_val, n, model_name):  \n",
    "    #inverse transform and convert to millions\n",
    "    original_val = to_millions(inverse_scaling(original_val)) \n",
    "    predicted_val = to_millions(inverse_scaling(predicted_val))\n",
    "    original_val_list = []\n",
    "    predicted_val_list = []\n",
    "    for k in range(n):\n",
    "        i = random.randint(0, len(predicted_val) - 1)\n",
    "        original_val_list.append(original_val[i])\n",
    "        predicted_val_list.append(predicted_val[i])\n",
    "    \n",
    "    original_val_df = pd.DataFrame(original_val_list)\n",
    "    predicted_val_df = pd.DataFrame(predicted_val_list)\n",
    "    \n",
    "    actual_vs_predicted = pd.concat([original_val_df, predicted_val_df], axis = 1)\n",
    "    \n",
    "    actual_vs_predicted.plot(kind = \"bar\", fontsize = 12, color = ['g','b'], width= 0.7)\n",
    "    plt.title(\"\\nUsing Categorical and Numerical Features\\n\" + model_name + \" : Actual Gross VS Predicted Gross(Random)\")\n",
    "    plt.ylabel('Gross (In Millions)', fontsize = 14)\n",
    "    plt.ylabel('Gross (In M', fontsize = 14)\n",
    "    plt.xticks([])\n",
    "    plt.legend([\"Actual Gross \", \"Predicted Gross\"], loc = 'center left', bbox_to_anchor = (1, 0.8))\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "        \n",
    "#Plot features\n",
    "#calculate mean\n",
    "def meanbyfeature(data, feature_name, meanby_feature):\n",
    "    mean_data = data.groupby(feature_name).mean()\n",
    "    mean = mean_data[meanby_feature]\n",
    "    mean_sort = mean.sort(meanby_feature, inplace = False, ascending = False)\n",
    "    return mean_sort\n",
    "    \n",
    "def plot(data, kind, title, n_rows):\n",
    "    plt.title(title, fontsize = 15)\n",
    "    data[:n_rows].plot(kind = kind)\n",
    "    plt.show()\n",
    "    \n",
    "def show_features(database):\n",
    "    print(\"\\n\",\"--------------------------------------------------------------------------------------------------------\")\n",
    "    database.info()\n",
    "    print(\"\\n\",\"--------------------------------------------------------------------------------------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_target_extracted(path):\n",
    "    original_data = data_import(path)\n",
    "    original_data_extracted = column_extract(original_data)\n",
    "    empty_value_row_removed = empty_row_column_val_drop(original_data_extracted)\n",
    "    database = data_fillna(empty_value_row_removed)\n",
    "    return database\n",
    "\n",
    "\n",
    "def preprocessing_catagory(data):\n",
    "    actor_1_name = preprocessing_categorical(data['actor_1_name'])\n",
    "    actor_2_name = preprocessing_categorical(data['actor_2_name'])\n",
    "    actor_3_name = preprocessing_categorical(data['actor_3_name'])\n",
    "    director_name = preprocessing_categorical(data['director_name'])\n",
    "    country = preprocessing_categorical(data['country'])\n",
    "    content_rating = preprocessing_categorical(data['content_rating'])\n",
    "    language = preprocessing_categorical(data['language'])\n",
    "\n",
    "    data_append = append_data(actor_1_name, actor_2_name)\n",
    "    data_append = append_data(data_append, actor_3_name)\n",
    "    data_append = append_data(data_append, director_name)\n",
    "    data_append = append_data(data_append, country)\n",
    "    data_append = append_data(data_append, content_rating)\n",
    "    data_append = append_data(data_append, language)\n",
    "    \n",
    "    return data_append\n",
    "\n",
    "def preprocessing_numerical(data):\n",
    "    data_list_numerical = list(zip(data['director_facebook_likes'], data['actor_1_facebook_likes'], \n",
    "                                   data['actor_2_facebook_likes'], data['actor_3_facebook_likes'], \n",
    "                                   data['cast_total_facebook_likes'], data['budget']))\n",
    "\n",
    "    data_numerical = np.array(data_list_numerical)\n",
    "    data_numerical = preprocessing_numerical_minmax(data_numerical)\n",
    "    return data_numerical\n",
    "\n",
    "def preprocessed_agregated_data(database): \n",
    "    numerical_data = preprocessing_numerical(database)\n",
    "    categorical_data = preprocessing_catagory(database)\n",
    "    all_data = append_data(numerical_data, categorical_data)\n",
    "    return all_data\n",
    "\n",
    "def regr_without_cross_validation_train_test_perform_plot(model, data, target, model_name):\n",
    "    train_data, test_data, train_target, test_target = train_test_split(data, target, test_size = 0.3, random_state = 0) \n",
    "    predicted_gross = regression_without_cross_validation(model, train_data, train_target, test_data)\n",
    "    regression_scores(test_target, predicted_gross, model_name)\n",
    "    prediction_performance_plot(test_target, predicted_gross, model_name)\n",
    "    prediction_performance_plot_range(test_target, predicted_gross, 200, 250, model_name)\n",
    "    prediction_performance_plot_random(test_target, predicted_gross, 100, model_name)\n",
    "    print_original_vs_predicted_rand(test_target, predicted_gross, 10, model_name)\n",
    "    bar_plot_original_vs_predicted_rand(test_target, predicted_gross, 20, model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['actor_1_name', 'actor_2_name', 'actor_3_name', 'director_name', 'country', 'content_rating', 'language', 'actor_1_facebook_likes', 'actor_2_facebook_likes', 'actor_3_facebook_likes', 'director_facebook_likes', 'cast_total_facebook_likes', 'gross', 'genres'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclean_movies.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdata_target_extracted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#data = data[(data.actor_1_facebook_likes > 0.0) & (data.actor_2_facebook_likes > 0.0) & (data.actor_3_facebook_likes > 0.0) & (data.director_facebook_likes > 0.0) & (data.cast_total_facebook_likes > 0.0) & (data.gross > 0.0)]\u001b[39;00m\n\u001b[0;32m      4\u001b[0m target \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgross\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mdata_target_extracted\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata_target_extracted\u001b[39m(path):\n\u001b[0;32m      2\u001b[0m     original_data \u001b[38;5;241m=\u001b[39m data_import(path)\n\u001b[1;32m----> 3\u001b[0m     original_data_extracted \u001b[38;5;241m=\u001b[39m \u001b[43mcolumn_extract\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     empty_value_row_removed \u001b[38;5;241m=\u001b[39m empty_row_column_val_drop(original_data_extracted)\n\u001b[0;32m      5\u001b[0m     database \u001b[38;5;241m=\u001b[39m data_fillna(empty_value_row_removed)\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mcolumn_extract\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcolumn_extract\u001b[39m(data):\n\u001b[1;32m---> 20\u001b[0m     selected_data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mall_selected_features\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m selected_data\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3510\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3511\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3513\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5796\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5793\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5794\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5796\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5798\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5800\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5859\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5858\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 5859\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['actor_1_name', 'actor_2_name', 'actor_3_name', 'director_name', 'country', 'content_rating', 'language', 'actor_1_facebook_likes', 'actor_2_facebook_likes', 'actor_3_facebook_likes', 'director_facebook_likes', 'cast_total_facebook_likes', 'gross', 'genres'] not in index\""
     ]
    }
   ],
   "source": [
    "\n",
    "path = \"clean_movies.csv\"\n",
    "data = data_target_extracted(path)\n",
    "#data = data[(data.actor_1_facebook_likes > 0.0) & (data.actor_2_facebook_likes > 0.0) & (data.actor_3_facebook_likes > 0.0) & (data.director_facebook_likes > 0.0) & (data.cast_total_facebook_likes > 0.0) & (data.gross > 0.0)]\n",
    "target = data['gross']\n",
    "database = data.drop('gross', 1)\n",
    "preprocessed_data = preprocessed_agregated_data(database)\n",
    "target = preprocessing_numerical_minmax(target)\n",
    "#print(\"_______________________________________________Random Forest Regressor Model_________________________________________\")\n",
    "randomForestRegressorModel = RandomForestRegressor()\n",
    "regression_with_cross_validation(randomForestRegressorModel, preprocessed_data, target, 5, \"Random Forest Regression\")\n",
    "regr_without_cross_validation_train_test_perform_plot(randomForestRegressorModel, preprocessed_data, target,\"Random Forest Regression\")\n",
    "#print(\"_____________________________________________________________________________________________________________________\")\n",
    "#print(\"_____________________________________________________________________________________________________________________\")\n",
    "#print(\"_______________________________________________Decision Tree Regressor Model_________________________________________\")\n",
    "#print(\"\")\n",
    "DecisionTreeRegressorModel = tree.DecisionTreeRegressor()\n",
    "regression_with_cross_validation(DecisionTreeRegressorModel, preprocessed_data, target, 5, \"Decision Tree Regression\")\n",
    "regr_without_cross_validation_train_test_perform_plot(DecisionTreeRegressorModel, preprocessed_data, target, \"Decision Tree Regression\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting\n",
    "actor_1_gross_mean_sort = meanbyfeature(data, 'actor_1_name', 'gross')\n",
    "plot(actor_1_gross_mean_sort, 'bar', 'Actor 1 Sorted by Mean Gross', 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m actor_2_gross_mean_sort \u001b[38;5;241m=\u001b[39m meanbyfeature(\u001b[43mdata\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactor_2_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgross\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m plot(actor_2_gross_mean_sort, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbar\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActor 2 Sorted by Mean Gross\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m30\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "actor_2_gross_mean_sort = meanbyfeature(data, 'actor_2_name', 'gross')\n",
    "plot(actor_2_gross_mean_sort, 'bar', 'Actor 2 Sorted by Mean Gross', 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m actor_3_gross_mean_sort \u001b[38;5;241m=\u001b[39m meanbyfeature(\u001b[43mdata\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactor_3_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgross\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m plot(actor_3_gross_mean_sort, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbar\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActor 3 Sorted by Mean Gross\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m30\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "actor_3_gross_mean_sort = meanbyfeature(data, 'actor_3_name', 'gross')\n",
    "plot(actor_3_gross_mean_sort, 'bar', 'Actor 3 Sorted by Mean Gross', 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m director_gross_sort \u001b[38;5;241m=\u001b[39m meanbyfeature(\u001b[43mdata\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdirector_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgross\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m plot(director_gross_sort, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbar\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDirector sorted by mean gross\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m30\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "director_gross_sort = meanbyfeature(data, 'director_name', 'gross')\n",
    "plot(director_gross_sort, 'bar', 'Director sorted by mean gross', 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m country_gross_sort \u001b[38;5;241m=\u001b[39m meanbyfeature(\u001b[43mdata\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcountry\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgross\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m plot(country_gross_sort, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbar\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountry sorted by mean gross\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m30\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "country_gross_sort = meanbyfeature(data, 'country', 'gross')\n",
    "plot(country_gross_sort, 'bar', 'Country sorted by mean gross', 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m content_rating_gross_sort \u001b[38;5;241m=\u001b[39m meanbyfeature(\u001b[43mdata\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent_rating\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgross\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m plot(content_rating_gross_sort, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbar\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent Rating Sorted by Mean Gross\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m30\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "content_rating_gross_sort = meanbyfeature(data, 'content_rating', 'gross')\n",
    "plot(content_rating_gross_sort, 'bar', 'Content Rating Sorted by Mean Gross', 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m corr \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mcorr()\n\u001b[0;32m      2\u001b[0m c \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mmatshow(corr)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mcolorbar(c)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "corr = data.corr()\n",
    "c = plt.matshow(corr)\n",
    "plt.colorbar(c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
